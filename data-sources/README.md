# Data Sources

This directory stores the scripts for obtaining raw data from a data source and the obtained raw data.

## Project Structure

### Directory

This directory is structured as:

```
ğŸ“‚data-sources
 â”£ ğŸ“‚{data-source-name-1}
 â”£ ğŸ“‚{data-source-name-2}
 â”£ ğŸ“‚...
 â”£ ğŸ“œunzip_data.py          - a script to unzip all the data files
 â”— ğŸ“œzip_data.py            - a script to zip all the data files
```

- **Usage of `unzip_data.py`**: Before carrying out data changes, the data files can be unzipped by `unzip_data.py`.
- **Usage of `zip_data.py`**: Before committing data changes, the data files should be zipped by `zip_data.py` to minimize their sizes.

### Subdirectory

Each subdirectory in this directory is structured as:

```
ğŸ“‚{data-source-name}
 â”£ ğŸ“‚output                         - a directory storing data files
 â”ƒ â”£ ğŸ“‚annotations
 â”ƒ â”ƒ â”£ ğŸ“œannotations.json           - image classification labels
 â”ƒ â”ƒ â”— ğŸ“œREADME.md
 â”ƒ â”£ ğŸ“‚imgs                         - fetched images (gitignored)
 â”ƒ â”ƒ â”£ ğŸ“œ{uuid1}.{ext1}
 â”ƒ â”ƒ â”£ ğŸ“œ{uuid2}.{ext2}
 â”ƒ â”ƒ â”— ğŸ“œ...
 â”ƒ â”£ ğŸ“‚metadata
 â”ƒ â”ƒ â”— ğŸ“œmetadata.jsonl             - fetched metadata
 â”ƒ â”£ ğŸ“‚metadata-processed
 â”ƒ â”ƒ â”£ ğŸ“œall.json                   - processed metadata of all the entries
 â”ƒ â”ƒ â”£ ğŸ“œall.zip                    - zipped processed metadata of all the entries
 â”ƒ â”ƒ â”£ ğŸ“œunlabeled.json             - processed metadata of unlabeled entries (gitignored)
 â”ƒ â”ƒ â”£ ğŸ“œunlabeled.zip              - zipped processed metadata of unlabeled entries (gitignored)
 â”ƒ â”ƒ â”£ ğŸ“œvisualizations.json        - processed metadata of entries labeled as vis
 â”ƒ â”ƒ â”— ğŸ“œvisualizations.zip         - zipped processed metadata of entries labeled as vis
 â”ƒ â”— ğŸ“œ.gitignore
 â”£ ğŸ“œ_querier.py                    - a package containing the querier instance
 â”£ ğŸ“œ_queries.py                    - a package containing the queries to be conducted
 â”£ ğŸ“œfetch_images.py                - a script to fetch images
 â”£ ğŸ“œfetch_metadata.py              - a script to fetch metadata
 â”£ ğŸ“œprocess_all_metadata.py        - a script to process metadata of all the entries
 â”£ ğŸ“œprocess_unlabeled_metadata.py  - a script to process metadata of unlabeled entries
 â”£ ğŸ“œprocess_vis_metadata.py        - a script to process metadata of entries labeled as vis
 â”— ğŸ“œREADME.md
```

### Subdirectory scripts

Each subdirectory contains Python scripts for maintaining the dataset.
Usage of scripts in each subdirectory:

- **Usage of `fetch_metadata.py`**: Fetch metadata and store them at `./output/metadata/metadata.jsonl`. Additional cache files may be created at `./output/metadata/query-return/`.
- **Usage of `fetch_images.py`**: Fetch images and store them at `./output/imgs/`. The images are fetched according to the metadata at `./output/metadata/metadata.jsonl`.
- **Usage of `process_unlabeled_metadata.py`**: Process the metadata entries at `./output/metadata/metadata.jsonl` that are unlabeled according to `./output/annotations/annotations.json`.
- **Usage of `process_vis_metadata.py`**: Process the metadata entries at `./output/metadata/metadata.jsonl` that are labeled as visualizations according to `./output/annotations/annotations.json`. The processing utilizes properties of corresponding images stored at `./output/imgs/`.
- **Usage of `process_all_metadata.py`**: Process all the metadata entries at `./output/metadata/metadata.jsonl`. This script mainly serves the debugging purpose.

A script can be executed with `poetry run python {script-name}.py`.
If the poetry virtual environment is already activated, a script can be executed directly with `python {script-name}.py`.
